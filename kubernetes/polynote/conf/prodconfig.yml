######### Polynote Configuration Template ##############################################################################
# To use, copy this template and name it `config.yml`
#
#    cp ./config-template.yml ./config.yml
#
# Now, uncomment the section of the config that you'd like to change.
#
########################################################################################################################

########## Server-level Configuration ################################
###
### These configurations are applied immediately when Polynote starts.
###
######################################################################

###############################################################################
# The host and port can be set by uncommenting and editing the following lines.
###############################################################################

listen:
  host: 0.0.0.0
#  host: 127.0.0.1
#  port: 8192

###############################################################################
# Security settings. Be careful with these!
###############################################################################

#security:
#  websocket_key: only_for_testing


############################################################################################
# Storage-related configuration. Locations are all relative to Polynote's working directory.
############################################################################################

storage:
  # The base directory Polynote should use when looking for notebooks. This location can be absolute or
  # relative to Polynote's working directory.
  dir: /opt/
  # These are additional mount points. Folders specified here will be 'mounted' into the base directory
  # and visible by their keys - so `foo: dir: bar` will show a folder `foo` in the UI that shows the contents of the
  # file system under `bar/`
  mounts:
    #   examples:
    #     dir: examples
    code:
      dir: /opt/src
    data:
      dir: /opt/data
    config:
      dir: /opt/config
    #   notebooks:
    #     dir: /opt/notebooks

    #  team_notebooks:
    #    dir: /shared/notebooks
  # The location Polynote puts various caches, such as virtual environments created for your notebooks.
  cache: tmp

##########################################################
# Configure the way Polynote runs Kernels and Interpreters
##########################################################

#behavior:
#  dependency_isolation: false
#  kernel_isolation: always
#  shared_packages:
#    - com.esoteric.kryo

########## Notebook Creation Configuration #######################################################
###
### These configurations are applied to *new notebooks* only.
### When a *new notebook* is created, its Notebook Configuration is copied from this configuration.
### They do *not* affect existing notebooks.
###
###################################################################################################

############################################################################################
# Default repositories. Uncommenting the following lines would add four default repositories
# which are inherited by new notebooks.
############################################################################################

repositories:
  #  - ivy:
  #      base: https://my-artifacts.org/artifacts/
  #  - ivy:
  #      base: https://my-custom-ivy-repo.org/artifacts/
  #      artifact_pattern: [orgPath]/[module](_[scalaVersion])(_[sbtVersion])/[revision]/[artifact]-[revision](-[classifier]).[ext]
  #      metadata_pattern: [orgPath]/[module](_[scalaVersion])(_[sbtVersion])/[revision]/[module](_[scalaVersion])(_[sbtVersion])-[revision]-ivy.xml
  #      changing: true
  - maven:
      base: http://central.maven.org/maven2/
  - maven:
      base: http://oss.sonatype.org/content/repositories/snapshots
      changing: true

############################################################################################
# Default dependencies. Uncommenting the following lines would add some default dependencies
# which are inherited by new notebooks.
############################################################################################

dependencies:
  scala:
    - https://repo1.maven.org/maven2/io/prestosql/presto-jdbc/331/presto-jdbc-331.jar
  #   - org.typelevel:cats-core_2.11:1.6.0
  #    - com.mycompany:my-library:jar:all:1.0.0
  python:
    - requests
    - koalas==1.6.0
    - pyspark-stubs==3.0.0.post1
    - scikit-learn==0.24.1
    - google-cloud-storage==1.35.1
    - PuLP==2.4
    - loguru==0.5.3
#   - pyspark==3.0.1
#    - urllib3==1.25.3

########################################################################################
# Default exclusions. Uncommenting the following lines would add some default exclusions
# which are inherited by new notebooks.
########################################################################################

#exclusions:
#  - com.google.guava:guava  # spark, update your guava already!!!

########## Notebook Runtime Configuration #########################################################################
###
### These configurations are applied to *all notebooks*.
### When a *new notebook* is created, its Notebook Configuration is copied from this configuration.
###
### When an existing notebook is *run*, these configurations are applied at runtime. Values present in the Notebook
### Configuration take precedence over values here. The Notebook Configuration is *not* modified.
###
### **Note** that this means they can affect reproducibility of your notebooks when you share them with others!
###
###################################################################################################################

###################################################################################################################
# Spark config params can be set by uncommenting and editing the following lines.
# To add additional spark configuration properties, add them as keys under `properties`.
# To set additional arguments to `spark-submit`, you can use the `spark_submit_args` property.
#
# By default, not all jars in SPARK_DIST_CLASSPATH are available to the Polynote compiler (i.e., to user-code
# inside cells). To use these jars (for example, if you want to use Hadoop APIs in your notebook without adding
# a Hadoop dependency), set the `dist_classpath_filter` to a valid regular expression that selects which JARs
# you want to use (there can be a huge number of JARs in SPARK_DIST_CLASSPATH, so it would be burdensome to
# include all of them by default.)
#
#################################################################################

spark:
  properties:
    spark.driver.memory: 24g
    # spark.executor.memory: 24g
    spark.sql.execution.arrow.pyspark.fallback.enabled: true # Optimizations enabled by arrow will fallback automatically
    # to non-optimized implementations if an error occurs.
    spark.sql.execution.arrow.pyspark.enabled: true
    spark.sql.execution.arrow.maxRecordsPerBatch: 20000
    # spark.sql.execution.pandas.udf.buffer.size
    spark.sql.files.ignoreCorruptFiles: true # Whether to ignore corrupt files
    spark.sql.files.maxPartitionBytes: "128MB" # maximum number of bytes to pack into a single partition when reading files.
    spark.sql.parquet.mergeSchema: true # Parquet data source merges schemas collected from all data files
    spark.sql.parquet.filterPushdown: true
    spark.sql.parquet.recordLevelFilter.enabled: true
    spark.sql.session.timeZone: "Asia/Kolkata"
    spark.sql.adaptive.enabled: true # re-optimizes the query plan in middle
    spark.sql.ansi.enabled: true
    spark.sql.cbo.enabled: true
    spark.driver.extraJavaOptions: "-XX:+UnlockExperimentalVMOptions"
    spark.executor.extraJavaOptions: "-XX:+UnlockExperimentalVMOptions"
    spark.python.worker.memory: "512m" # "2g" Amount of memory to use per python worker process during aggregation
    # spark.jars
    spark.ui.showConsoleProgress: true
    spark.memory.fraction: 0.6
    # spark.dynamicAllocation.enabled: true # scales the number of executors registered with this application up and down based on the workload
    # spark.driver.userClasspathFirst: true
    # spark.executor.userClasspathFirst: true
    # spark_submit_args: "--some --arguments"
    # dist_classpath_filter: hadoop.*\.jar


########## Front-end Configuration ################################################################################
###
### These configurations affect the behavior of the front-end. You can modify the behavior by uncommenting the
### following lines and editing the properties.
###
###################################################################################################################

#ui:
#  # The URI relative to the server host where Polynote is mounted. You can edit this if mounting Polynote at a
#  # different location behind a reverse proxy. This value is placed in the <base> tag.
#  base_uri: /

############################################################################################
# Credentials. This list contains the list of credentials used to access the repositories
############################################################################################

#credentials:
#  coursier:
#    path: ~/.config/coursier/credentials.properties

#############################################################################################################
# Environment variables. This map gets merged with the notebook config's environment variable map at runtime.
#############################################################################################################

#env:
#  foo: bar